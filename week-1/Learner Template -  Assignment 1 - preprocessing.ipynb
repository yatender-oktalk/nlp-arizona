{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Text Acquisition and Pre-processing\n",
    "\n",
    "In this assignment you will practice obtaining, extracting, cleaning and pre-processing text from an online source. The objective is to obtain the text from a web page and generate a **pandas** DataFrame containing the text segmented, tokenized and with different types of linguistic annotations.\n",
    "\n",
    "You will work with the following objects and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Text Extraction   - [3 Marks]\n",
    "\n",
    "The text you are going to work with corresponds to the following post from the Food and Agriculture Organization of the United Nations website: [World food prices dip in December](https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en).\n",
    "\n",
    "In a more realistic scenario, you should download the html document yourself. This could be done with the following code snippet:\n",
    "\n",
    ">```python\n",
    "import requests\n",
    "URL = \"https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en\"\n",
    "page = requests.get(URL)\n",
    "html_content = page.content\n",
    "\n",
    "However, for this assignment, you are provided with the downloaded document. The file`world-food-prices.html` can be found in the same directory as this notebook and it can be opened as a regular text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>\\n\\tWorld food prices dip in December\\n</title> <script src=\"/ScriptResource.axd?d=okuX3IVIBwfJlfEQK32K3hu4wA2qYZOscmtsXGLNMaT1SeSa2ByRKpPz9pkmicdQmLZjrfXbzQg-t-PYtREZ1mv-AHy-XqG8V1C8KEuJc1LwVjfZ2AWtsXusqOzwjxwAkWajaiTob5rdLJ_1Q_rhyISygdJ2WS4kb3-Mf0bSt_7dAdqZ2JnDovQKGlnv0vvH0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"/ScriptResource.axd?d=ePnjFy9PuY6CB3GWMX-b_9Fw4jG3rW51lh6cTRiQ1f_9YOhRVOpDf4gVRQwVzn4JRlDVp-Aj_GWhYCgMY8uVHBZj_w4a27EVOxonvJSMs3yERFILsgdOHu7up3GVU-jExdmK0YWhyY1E0W4ye5rzFrSYUigZQBN7nFt18-5XwfQs2ZTBZ5-Na5q3Phaw58Dx0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"https://cse.google.com/cse.js?cx=018170620143701104933%3Aqq82jsfba7w\" type=\"text/javascript\"></script><link href=\"/ResourcePackages/FAO/assets/dist/css/bootstrap.min.css?v=5.2.0&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <link href=\"/ResourcePackages/FAO/assets/dist/css/fao-theme.min.css?v=2.6.6&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <!-- Google Tag Manager -->\\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\\'gtm.start\\':\\nnew Date().getTime(),event:\\'gtm.js\\'});var f=d.getElementsByTagName(s)[0],\\nj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';j.async=true;j.src=\\n\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n})(window,document,\\'script\\',\\'d'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"world-food-prices.html\", encoding=\"utf8\") as html_file:\n",
    "    html_content = html_file.read()\n",
    "html_content[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    " As you can see the document contains a lot of html tags as well as some **javascript** code. The text also includes fields that are not of interest, such as the navigation menu of the web page. The goal of the first step in this assignment is to extract only the text from the body of the post.   \n",
    "\n",
    "To do this, you must complete the code for the `extract_text` function. This function should parse the content of the html document using the **BeatifulSoup** library, find the html element containing the text of the body of the post, and extract such text. The body of the post is contained by the element with the following **id**: `\"Contentplaceholder1_C011_Col00\"`. Review the [BeautifullSoup documentation](https://beautiful-soup-4.readthedocs.io/en/latest/index.html) to learn how to perform these steps.\n",
    "\n",
    "\n",
    "The function must return the text extracted of which the first 579 characters should look like this:\n",
    "\n",
    "\n",
    "><pre>Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food                                 A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')    \n",
    "    return soup.find(id='Contentplaceholder1_C011_Col00').text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. However, for 2022 as a whole, the index, which tracks monthly changes in the international prices of commonly-traded food commodities, averaged 143.7 points, 14.3 percent higher than the average value over 2021. “Calmer food commodity prices are welcome after two very volatile years,” said FAO Chief Economist Maximo Torero. “It is important to remain vigilant and keep a strong focus on mitigating global food insecurity given that world food prices remain at elevated levels, with many staples near record highs, and with prices of rice increasing, and still many risks associated with future supplies” Vegetable oil world quotations led the decrease, with the FAO Vegetable Oil Price Index down 6.7 percent from November to reach its lowest level since February 2021. International quotations for palm, soy, rapeseed and sunflowerseed oils all declined in December, driven by subdued global import demand and prospects of seasonally rising soy oil production in South America as well as declining crude oil prices.The FAO Cereal Price Index decreased 1.9 percent from November. Ongoing harvests in the southern hemisphere boosted wheat exportable supplies, while strong competition from Brazil drove down world maize prices. Conversely, international rice prices rose, buoyed by Asian buying and currency appreciation against the United States dollar for exporting countries. The FAO Meat Price Index in December dropped by 1.2 percent from November, with lower world prices of bovine and poultry meats outweighing higher pig and ovine meat prices. International bovine meat prices were impacted by lacklustre global demand for medium-term supplies, while more-than-adequate export supplies pushed down poultry meat prices. Pig meat prices rose on the back of strong internal holiday demand, especially in Europe, The FAO Dairy Price Index increased by 1.2 percent in December, following five months of consecutive declines. Higher international cheese prices, reflecting tightening market conditions, drove the monthly increase in the index, while international quotations for butter and milk powder declined. The FAO Sugar Price Index also rose, increasing by 2.4 percent from November, mostly due to concerns over the impact of adverse weather conditions on crop yields in India and sugarcane crushing delays in Thailand and Australia. Looking back on 2022As noted, the FAO Food Price Index average over 2022 was notably higher than the previous year, which on top of large increases in 2021 catalyzed significant strains and food security concerns for lower-income food-importing countries and the adoption, inspired by FAO, of a “Food Shock Window” lending facility by the International Monetary Fund. World prices of wheat and maize reached record highs over the year. The average value of the FAO Vegetable Oil Price Index for all of 2022 reached a new record high, while the FAO Dairy Price Index and Meat Price Index marked their highest full-year levels since 1990.More details are available here.\\n\\n\\nMore on this topic\\nFAO Food Price IndexFAO's most recent Cereal Supply and Demand BriefAMIS: Market MonitorAgricultural Market Information System (AMIS)FAO Markets and Trade\\n\\n\\n\\n\\n\\n\\n\\nContact\\n\\nChristopher Emsden\\nFAO News and Media (Rome)\\n(+39) 06 570 53291\\n[email\\xa0protected]\\n\\n\\nFAO News and Media\\n\\n(+39) 06 570 53625\\n[email\\xa0protected]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')    \n",
    "placeholder_data = soup.find(id='Contentplaceholder1_C011_Col00').text\n",
    "placeholder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = extract_text(html_content)\n",
    "extracted_text = text[:580]\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Text Cleanup  - [3 Marks]\n",
    "\n",
    " The text extracted by `extract_text` is not still ready to use. It contains several newline characters and additional spaces that make the text noisy. In the next step of the assignment, you must complete the code for the function `clean_text`. The function should take the text and delete all those newline characters and extra blank spaces. The function should also add a period to the end of those sentences that do not originally contain it, for example, `World food prices dip in December` or `06/01/2023`.\n",
    "\n",
    "You can solve this exercise using the **Python** built-in [string methods](https://docs.python.org/3.9/library/stdtypes.html?highlight=replace#str), such as `replace`, or by [regular expressions](https://docs.python.org/3.9/library/re.html?highlight=re#module-re).\n",
    "\n",
    "The `extract_text` function must return the cleaned text of which the first 499 characters should look like this:\n",
    "\n",
    ">'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    text = re.sub(r'[\\r\\n]+', '. ', text)\n",
    "    text = re.sub(r'\\.{2,}', '. ', text)\n",
    "    text = re.sub(r'\\s*\\.\\s*\\.', '. ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s*+\\.', '.', text)\n",
    "    return text[1:].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(text)\n",
    "cleaned_str = cleaned_text[:499]\n",
    "\n",
    "## Validate the function output with the expected output\n",
    "expected_str = 'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier.'\n",
    "assert cleaned_str == expected_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Pre-processing  - [3 Marks]\n",
    "\n",
    "Once the text has been extracted and cleaned up, the next step you must take is to pre-process it. For this, in this assignment, you are going to use the [spaCy](https://spacy.io/) library. This library is an advanced NLP toolkit that allows to execute various pre-processing steps as well as different NLP tasks. **spaCy** provides trained [pipelines](https://spacy.io/usage/processing-pipelines) for a variety of languages that can be installed as individual **Python** modules and include [linguistic featues](https://spacy.io/usage/linguistic-features) such as:\n",
    "\n",
    "- Sentence Segmentation\n",
    "- Tokenization\n",
    "- Stemming and Lemmatization\n",
    "- Stopwords\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Named Entity Recognition\n",
    "- Word Embeddings\n",
    "\n",
    "In this exercise, you will work with the [English pipeline optimized for CPU](https://spacy.io/models/en#en_core_web_sm) that can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    " You must complete the code for the `preprocess_text` function. This function takes the text and a **spaCy** pipeline as input and should run that pipeline on the text. The function must return a [Doc](https://spacy.io/api/doc) object. Check the [spaCy 101](https://spacy.io/usage/spacy-101) documentation to learn how to apply the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, nlp):\n",
    "    #\n",
    "    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n",
    "    #\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = process_text(cleaned_text, nlp)\n",
    "all(map(doc.has_annotation, [\"LEMMA\", \"POS\", \"ENT_TYPE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Creating a DataFrame  - [3 Marks]\n",
    "\n",
    "In the next exercise, you will create a [pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that will contain some of the linguistic annotations from the `Doc` object obtained in the previous step. Loading the data into a `DataFrame` provides some advantages such as a better integration with other **Python** machine learning libraries or the option to save the data in a csv file.\n",
    "\n",
    "The goal is to create a `DataFrame` that contains a row per each token in the `Doc` and the following columns:\n",
    "- *sent_id*: The id of the sentence the token belongs to. It represents the position of the sentence in the `Doc`, starting by 0.\n",
    "- *token_id*: The id of the token. It represents the position of the token in the sentence, starting by 0.\n",
    "- *text*: The original text of the token.\n",
    "- *lemma*: The lemmatization of the token.\n",
    "- *pos*: The part-of-speech of the token.\n",
    "- *ent*: The entity type of the token returned by the Named Entity Recognition component.\n",
    "\n",
    "You must complete the code for the `to_dataframe` function. This function takes the [Doc](https://spacy.io/api/doc) object and must return the `DataFrame` described above. The function should iterate over the sentences in the `Doc` (each sentence is a [Span](https://spacy.io/api/span) object) and, for each sentence, it should iterate over its tokens (each token is a [Token](https://spacy.io/api/token) object). For each token, `to_dataframe` should obtain the values to fill the *text*, *lemma*, *pos* and *ent* columns of the `DataFrame`. For example, the content of the `DataFrame` for the setence with *sent_id* equal to 1, corresponding to the second sentence in the `Doc`, should look like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text    | lemma   | pos   | ent   |\n",
    "|---:|----------:|-----------:|:--------|:--------|:------|:------|\n",
    "|  7 |         1 |          0 | FAO     | FAO     | PROPN | ORG   |\n",
    "|  8 |         1 |          1 | Food    | Food    | PROPN | ORG   |\n",
    "|  9 |         1 |          2 | Price   | Price   | PROPN | ORG   |\n",
    "| 10 |         1 |          3 | Index   | Index   | PROPN | ORG   |\n",
    "| 11 |         1 |          4 | ends    | end     | VERB  |       |\n",
    "| 12 |         1 |          5 | 2022    | 2022    | NUM   | DATE  |\n",
    "| 13 |         1 |          6 | lower   | low     | ADJ   |       |\n",
    "| 14 |         1 |          7 | than    | than    | ADP   |       |\n",
    "| 15 |         1 |          8 | a       | a       | DET   | DATE  |\n",
    "| 16 |         1 |          9 | year    | year    | NOUN  | DATE  |\n",
    "| 17 |         1 |         10 | earlier | early   | ADV   | DATE  |\n",
    "| 18 |         1 |         11 | .       | .       | PUNCT |       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_dataframe(doc):\n",
    "    \"\"\"\n",
    "    Convert a spaCy Doc object into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - doc (spacy.tokens.Doc): The processed text as a spaCy Doc object.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing the linguistic features of the text.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for sent_id, sentence in enumerate(doc.sents):\n",
    "        for token_id, token in enumerate(sentence):\n",
    "            # Extract the values for each token\n",
    "            row = {\n",
    "                \"sent_id\": sent_id,\n",
    "                \"token_id\": token_id,\n",
    "                \"text\": token.text,\n",
    "                \"lemma\": token.lemma_,\n",
    "                \"pos\": token.pos_,\n",
    "                \"ent\": token.ent_type_ if token.ent_type_ else \"\"\n",
    "            }\n",
    "            data.append(row)\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    return pd.DataFrame(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FAO</td>\n",
       "      <td>FAO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Price</td>\n",
       "      <td>Price</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ends</td>\n",
       "      <td>end</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>lower</td>\n",
       "      <td>low</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>than</td>\n",
       "      <td>than</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>earlier</td>\n",
       "      <td>early</td>\n",
       "      <td>ADV</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id  token_id     text  lemma    pos   ent\n",
       "7         1         0      FAO    FAO  PROPN   ORG\n",
       "8         1         1     Food   Food  PROPN   ORG\n",
       "9         1         2    Price  Price  PROPN      \n",
       "10        1         3    Index  Index  PROPN      \n",
       "11        1         4     ends    end   VERB      \n",
       "12        1         5     2022   2022    NUM  DATE\n",
       "13        1         6    lower    low    ADJ      \n",
       "14        1         7     than   than    ADP      \n",
       "15        1         8        a      a    DET  DATE\n",
       "16        1         9     year   year   NOUN  DATE\n",
       "17        1        10  earlier  early    ADV  DATE\n",
       "18        1        11        .      .  PUNCT      "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Cutomizing the Tokenizer  - [3 Marks]\n",
    "\n",
    "The default components of a **spaCy** pipeline will not always behave according to the needs of your projects. For example, the default tokenizer of the `en_core_web_sm` pipeline does not always splits dates in `month/day/year` format into `month`, `day` and `year`. This is the case for the sentence with *sent_id* equal to 4 that only includes a date in that format:\n",
    "\n",
    "|    |   sent_id |   token_id | text       | lemma      | pos   | ent   |\n",
    "|---:|----------:|-----------:|:-----------|:-----------|:------|:------|\n",
    "| 32 |         4 |          0 | 06/01/2023 | 06/01/2023 | NUM   |       |\n",
    "| 33 |         4 |          1 | .          | .          | PUNCT |       |\n",
    "\n",
    "The goal of the last exercise of this task is to update the `en_core_web_sm` pipeline with a custom tokenizer that forces the splitting of dates in `month/day/year` format so that the sentence above looks like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text   | lemma   | pos   | ent      |\n",
    "|---:|----------:|-----------:|:-------|:--------|:------|:---------|\n",
    "| 32 |         4 |          0 | 06     | 06      | NUM   | CARDINAL |\n",
    "| 33 |         4 |          1 | /      | /       | SYM   |          |\n",
    "| 34 |         4 |          2 | 01     | 01      | NUM   |          |\n",
    "| 35 |         4 |          3 | /      | /       | SYM   |          |\n",
    "| 36 |         4 |          4 | 2023   | 2023    | NUM   |          |\n",
    "| 37 |         4 |          5 | .      | .       | PUNCT |          |\n",
    "\n",
    "You must complete the code for the `customize_tokenizer` function. The function takes the **spaCy** pipeline as input. It should updated the infixes rules of the tokenizer and return the updated version of the pipeline including the customized tokenizer. The `Tokenizer` must keep the default vocabulary and all the default prefixes, infixes and suffixes rules of the pipeline. You should only update the infixes rules adding a regular expression that captures slash (`/`) characters. The `Tokenizer` should **not** include special cases or rules for token and url matching. Check the [spacy's documentation](https://spacy.io/usage/linguistic-features#native-tokenizers) to learn how to customize the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "def customize_tokenizer(nlp):\n",
    "    infix_patterns = nlp.Defaults.infixes + [r'\\/']\n",
    "    infix_re = compile_infix_regex(infix_patterns)\n",
    "    tokenizer = Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "                          suffix_search=nlp.tokenizer.suffix_search,\n",
    "                          infix_finditer=infix_re.finditer,\n",
    "                          token_match=nlp.tokenizer.token_match)\n",
    "\n",
    "    nlp.tokenizer = tokenizer\n",
    "\n",
    "    return nlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id  token_id  text lemma    pos   ent\n",
       "33        4         0    06    06    NUM  DATE\n",
       "34        4         1     /     /    SYM  DATE\n",
       "35        4         2    01    01    NUM  DATE\n",
       "36        4         3     /     /    SYM  DATE\n",
       "37        4         4  2023  2023    NUM  DATE\n",
       "38        4         5     .     .  PUNCT      "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customized_nlp = customize_tokenizer(nlp)\n",
    "doc = process_text(cleaned_text, customized_nlp)\n",
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 4]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
