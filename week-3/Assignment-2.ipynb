{"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"N7bnDuXGLCKi"},"source":["# Text Classification\n","\n","In this assignment, you will work on the [OffensEval](https://sites.google.com/site/offensevalsharedtask/) shared task. This challenge has been part of the 2019 and 2020 editions of SemEval and focuses on the identification of offensive language in social media platforms. In particular, you are solving subtasks A and B of the 2019 edition:\n","\n","* **SubTask A: Offensive language identification.** The goal of this subtask is to discriminate between offensive and non-offensive posts. Offensive posts include insults, threats, and other type of non-acceptable language. This subtask can be addressed as a Binary Text Classication problem.\n","\n","\n","* **SubTask B: Automatic categorization of offense types.** The goal is to predict if the offensive post is targeted or not. A post is considered targeted if it contains insults or threats to an individual or group. An untargeted offensive post contains non-acceptable language that is not targeted at anyone in particular. In this assignment, you will work on a version of this subtask where the goal is to classify posts as targeted, untargeted and non-offensive. This version of the subtask can be addressed as a Multiclass Text Classication problem.\n","\n","You will work with [scikit-learn](https://scikit-learn.org/stable/), a **Python** Machine Learning library that provides a wide range of tools, including some for text data. Specifically, you will use the following objects and functions:"]},{"cell_type":"code","execution_count":23,"metadata":{"deletable":false,"editable":false,"id":"owb0L7xTLCKm"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import f1_score, accuracy_score"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"Vh4PTpmvLCKn"},"source":["The data for the assignment consists of 13240 tweets for training and 860 tweets for test with annotations for both **SubTask A** (*True* or *False*) and **SubTask B** (*TIN*, *UNT* and *NOT*). The dataset also includes the Sentiment Analysis of the tweets that you will use later in the assignment. The dataset can be loaded into two `DataFrames` as follows:"]},{"cell_type":"code","execution_count":24,"metadata":{"deletable":false,"editable":false,"id":"XPdIe-SnLCKo"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>sentiment</th>\n","      <th>subtask_a</th>\n","      <th>subtask_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>neutral</td>\n","      <td>True</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>negative</td>\n","      <td>True</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>neutral</td>\n","      <td>False</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>negative</td>\n","      <td>True</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>negative</td>\n","      <td>False</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13235</th>\n","      <td>@USER Sometimes I get strong vibes from people...</td>\n","      <td>negative</td>\n","      <td>True</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>13236</th>\n","      <td>Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...</td>\n","      <td>positive</td>\n","      <td>False</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>13237</th>\n","      <td>@USER And why report this garbage.  We don't g...</td>\n","      <td>negative</td>\n","      <td>True</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>13238</th>\n","      <td>@USER Pussy</td>\n","      <td>negative</td>\n","      <td>True</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>13239</th>\n","      <td>#Spanishrevenge vs. #justice #HumanRights and ...</td>\n","      <td>negative</td>\n","      <td>False</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13240 rows × 4 columns</p>\n","</div>"],"text/plain":["                                                   tweet sentiment  subtask_a  \\\n","0      @USER She should ask a few native Americans wh...   neutral       True   \n","1      @USER @USER Go home you’re drunk!!! @USER #MAG...  negative       True   \n","2      Amazon is investigating Chinese employees who ...   neutral      False   \n","3      @USER Someone should'veTaken\" this piece of sh...  negative       True   \n","4      @USER @USER Obama wanted liberals &amp; illega...  negative      False   \n","...                                                  ...       ...        ...   \n","13235  @USER Sometimes I get strong vibes from people...  negative       True   \n","13236  Benidorm ✅  Creamfields ✅  Maga ✅   Not too sh...  positive      False   \n","13237  @USER And why report this garbage.  We don't g...  negative       True   \n","13238                                        @USER Pussy  negative       True   \n","13239  #Spanishrevenge vs. #justice #HumanRights and ...  negative      False   \n","\n","      subtask_b  \n","0           UNT  \n","1           TIN  \n","2           NOT  \n","3           UNT  \n","4           NOT  \n","...         ...  \n","13235       TIN  \n","13236       NOT  \n","13237       TIN  \n","13238       UNT  \n","13239       NOT  \n","\n","[13240 rows x 4 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")\n","test = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n","train[[\"tweet\", \"sentiment\", \"subtask_a\", \"subtask_b\"]]"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 13240 entries, 0 to 13239\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   id         13240 non-null  int64 \n"," 1   tweet      13240 non-null  object\n"," 2   subtask_a  13240 non-null  bool  \n"," 3   subtask_b  13240 non-null  object\n"," 4   subtask_c  3876 non-null   object\n"," 5   sentiment  13240 non-null  object\n","dtypes: bool(1), int64(1), object(4)\n","memory usage: 530.2+ KB\n"]}],"source":["train.info()\n"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"-g-4X6LwLCKo"},"source":["## Text Representation - [ 6 Marks]\n","\n","In order to apply Text Classification for both subtasks, we first need to convert the text of the tweets into numerical feature vectors. For this assignment, you are using a bag-of-words based on tf-idf. This representation can be obtained with **scikit-learn** using [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer). `TfidfVectorizer` provides a number of pre-processing steps, such as tokenization and stop-words, and other options to represent the text.\n","\n","You must complete the code for the `create_tfidfvectorizer` function. The function must create and return a `TfidfVectorizer` with all parameters at their default value. Check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer) to learn how."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"OFGJ0EkYLCKp"},"outputs":[],"source":["def create_tfidfvectorizer():   # 3 Marks\n","    return TfidfVectorizer()"]},{"cell_type":"code","execution_count":27,"metadata":{"deletable":false,"editable":false,"id":"xTUb7DL8LCKp"},"outputs":[],"source":["vectorizer = create_tfidfvectorizer()"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"Z-bZhAsJLCKp"},"source":["Now that you have created the `TfidfVectorizer`, the next step is to apply it to the dataset and get the representation of the tweets. For this, `TfidfVectorizer` first needs to learn the vocabulary and idf values from the train set. Then, it can be used to transform both the train and test sets. When applied to the text data, `TfidfVectorizer` will pre-process it according to the parameters used.\n","\n","You must complete the code for the `run_vectorizer` function. The function takes the vectorizer created previously, and the tweets of the train and test sets. The function should train the vectorizer on the train text to learn the vocabulary and the idf values, and apply it to transform both the train and test tweets. The expected output is the result of these transformations where each tweet should be represented with a vector of 19083 dimensions:\n","> Shape of train input data: (13240, 19083)  \n","Shape of test input data: (860, 19083)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"FVGzD7nCLCKq"},"outputs":[],"source":["def run_vectorizer(vectorizer, train, test):   # 3 Marks\n","    vectorizer.fit(train)\n","    train_x = vectorizer.transform(train)\n","    test_x = vectorizer.transform(test)\n","    return train_x, test_x"]},{"cell_type":"code","execution_count":29,"metadata":{"deletable":false,"editable":false,"id":"23C5-HMhLCKq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of train input data: (13240, 19083)\n","Shape of test input data: (860, 19083)\n"]}],"source":["train_x, test_x = run_vectorizer(vectorizer, train[\"tweet\"], test[\"tweet\"])\n","print(f\"Shape of train input data: {train_x.get_shape()}\")\n","print(f\"Shape of test input data: {test_x.get_shape()}\")"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"yIOkH2MXLCKr"},"source":["## Logistic Regression - [8 Marks]\n","\n","Having obtained the feature vectors from the text, you can proceed with training a classifier to make predictions about the offensive language of a tweet. You will begin by creating a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) with **scikit-learn**. To keep the exercise simple, you are going to use the default options which include the *one-vs-all* strategy for the Multiclass case and the [Limited-memory BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) algorithm for optimization. The [SGDClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) allows implementing a Logistic Regression classifier that works with Stochastic Gradient Descent, but you won't use it for this assignment.\n","\n","You must complete the code for the `create_model` function. The functions should create and return a `LogisticRegression` with the default options, just increase the maximum number of training iterations to 1000 to ensure that the model converges. "]},{"cell_type":"code","execution_count":30,"metadata":{"id":"BC4om8scLCKr"},"outputs":[],"source":["def create_model(max_iter=1000):   # 3 Marks\n","    return LogisticRegression(max_iter=max_iter)"]},{"cell_type":"code","execution_count":31,"metadata":{"deletable":false,"editable":false,"id":"yJ3x_pfmLCKr"},"outputs":[],"source":["model = create_model()"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"iGCjOLvTLCKs"},"source":["Just based on the target labels you use for training, the `LogisticRegression` you have created is able to automatically recognize the type of classification problem you are working on, Binary or Multiclass. In the following exercise, you will implement the code to train the model and make predictions on the test set. The same solution will be used for both **SubTask A** and **SubTask B**.\n","\n","You must complete the code for the `run_model` function. The function takes input as the model, the train feature vectors, the train target labels and the test feature vectors. The function should train the model using the train features and labels, and return the predictions for the given test. "]},{"cell_type":"code","execution_count":32,"metadata":{"id":"LfRYuhppLCKs"},"outputs":[],"source":["def run_model(model, train_x, train_y, test_x):   # 5 Marks\n","    #\n","    #  REPLACE THE pass STATEMENT WITH YOUR CODE\n","    #\n","    clf = model.fit(train_x, train_y)\n","    return clf.predict(test_x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":33,"metadata":{"deletable":false,"editable":false,"id":"Lxxcd-ogLCKs"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_a</th>\n","      <th>prediction_a</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet  subtask_a  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       True   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...      False   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...      False   \n","3    13876  #Watching #Boomer getting the news that she is...      False   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       True   \n","..     ...                                                ...        ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       True   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...      False   \n","857  67018  3 people just unfollowed me for talking about ...       True   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...      False   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL      False   \n","\n","     prediction_a  \n","0           False  \n","1           False  \n","2           False  \n","3           False  \n","4           False  \n","..            ...  \n","855         False  \n","856         False  \n","857          True  \n","858         False  \n","859         False  \n","\n","[860 rows x 4 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["prediction = run_model(model, train_x, train[\"subtask_a\"], test_x)\n","test['prediction_a'] = prediction\n","test[['id', 'tweet', 'subtask_a', 'prediction_a']]"]},{"cell_type":"code","execution_count":34,"metadata":{"deletable":false,"editable":false,"id":"vliW1HTrLCKs"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_b</th>\n","      <th>prediction_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>TIN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>TIN</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>TIN</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>UNT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet subtask_b  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...       NOT   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT   \n","3    13876  #Watching #Boomer getting the news that she is...       NOT   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       TIN   \n","..     ...                                                ...       ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       TIN   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...       NOT   \n","857  67018  3 people just unfollowed me for talking about ...       UNT   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...       NOT   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL       NOT   \n","\n","    prediction_b  \n","0            TIN  \n","1            NOT  \n","2            NOT  \n","3            NOT  \n","4            NOT  \n","..           ...  \n","855          NOT  \n","856          NOT  \n","857          NOT  \n","858          NOT  \n","859          NOT  \n","\n","[860 rows x 4 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["prediction = run_model(model, train_x, train[\"subtask_b\"], test_x)\n","test['prediction_b'] = prediction\n","test[['id', 'tweet', 'subtask_b', 'prediction_b']]"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"9KmGPo6ZLCKs"},"source":["You can now evaluate the performance of the `LogisticRegression` on the test set by computing different metrics with the true labels and the predictions obtained in the previous step. **SubTask A** can be evaluated with `accuracy` and `binary f1`, while for **SubTask B** `micro f1` and `macro f1` can be applied. If all went well, you should see results like the following:\n","> \\*\\*\\* SubTask A \\*\\*\\*  \n","accuracy: 0.80  \n","binary f1: 0.49  \n",">\n","> \\*\\*\\* SubTask B \\*\\*\\*    \n","micro f1: 0.78  \n","macro f1: 0.46"]},{"cell_type":"code","execution_count":35,"metadata":{"deletable":false,"editable":false,"id":"Qp4mT-mVLCKt"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** SubTask A ***\n","accuracy: 0.80\n","binary f1: 0.49\n","\n","*** SubTask B ***\n","micro f1: 0.78\n","macro f1: 0.46\n"]}],"source":["print(\"*** SubTask A ***\")\n","print(f\"accuracy: {accuracy_score(test['subtask_a'], test['prediction_a']):0.2f}\")\n","print(f\"binary f1: {f1_score(test['subtask_a'], test['prediction_a'], average='binary'):0.2f}\")\n","print(\"\")\n","print(\"*** SubTask B ***\")\n","print(f\"micro f1: {f1_score(test['subtask_b'], test['prediction_b'], average='micro'):0.2f}\")\n","print(f\"macro f1: {f1_score(test['subtask_b'], test['prediction_b'], average='macro'):0.2f}\")"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"CHGuatt4LCKt"},"source":["## Balancing the Dataset - [3 Marks]\n","\n","The differences observed between the metrics used in the above evaluation indicate that the **OfensEval** dataset is not balanced. In **SubTask A**, getting an `accuracy` much higher than the `binary f1` can mean that the number of `False` cases is larger than the number of `True` cases. Similarly, obtaining very different `micro f1` and `macro f1` scores in **SubTask B** is a hint that some of the classes are more frequent than others. This can be verified with the following code lines:\n",">```python \n","train.groupby(by=\"subtask_a\")[[\"tweet\"]].count().reset_index()\n","\n","|    | subtask_a   |   tweet |\n","|---:|:------------|--------:|\n","|  0 | False       |    8840 |\n","|  1 | True        |    4400 |\n","\n",">```python \n","train.groupby(by=\"subtask_b\")[[\"tweet\"]].count().reset_index()\n","\n","|    | subtask_b   |   tweet |\n","|---:|:------------|--------:|\n","|  0 | NOT         |    8840 |\n","|  1 | TIN         |    3876 |\n","|  2 | UNT         |     524 |\n","\n","One solution that can mitigate this problem is to assign weights to the classes in a way that reduces the influence of the most frequent ones. **Scikit-learn** allows easily applying such approach by setting the appropriate option when creating the model. The goal of the next exercise is to create a new version of the `LogisticRegression` that handles the unbalanced dataset better.\n","\n","You must complete the code for the `create_balanced_model` function. The function should create and return a `LogisticRegression` equal to the one created by `create_model` with the only difference being that this version automatically adjusts class weights. Check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to learn which parameter to set."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"2gdEDM7CLCKt"},"outputs":[],"source":["def create_balanced_model():   # 3 Marks\n","    return LogisticRegression(class_weight='balanced', max_iter=1000)"]},{"cell_type":"code","execution_count":37,"metadata":{"deletable":false,"editable":false,"id":"Mcv2-t1ELCKt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_a</th>\n","      <th>prediction_balanced_a</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet  subtask_a  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       True   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...      False   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...      False   \n","3    13876  #Watching #Boomer getting the news that she is...      False   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       True   \n","..     ...                                                ...        ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       True   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...      False   \n","857  67018  3 people just unfollowed me for talking about ...       True   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...      False   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL      False   \n","\n","     prediction_balanced_a  \n","0                     True  \n","1                    False  \n","2                    False  \n","3                    False  \n","4                    False  \n","..                     ...  \n","855                  False  \n","856                  False  \n","857                   True  \n","858                   True  \n","859                  False  \n","\n","[860 rows x 4 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["balanced_model = create_balanced_model()\n","prediction = run_model(balanced_model, train_x, train[\"subtask_a\"], test_x)\n","test['prediction_balanced_a'] = prediction\n","test[['id', 'tweet', 'subtask_a', 'prediction_balanced_a']]"]},{"cell_type":"code","execution_count":38,"metadata":{"deletable":false,"editable":false,"id":"60QKAW5YLCKt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_b</th>\n","      <th>prediction_balanced_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>TIN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>NOT</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>TIN</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>TIN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>UNT</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet subtask_b  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...       NOT   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT   \n","3    13876  #Watching #Boomer getting the news that she is...       NOT   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       TIN   \n","..     ...                                                ...       ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       TIN   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...       NOT   \n","857  67018  3 people just unfollowed me for talking about ...       UNT   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...       NOT   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL       NOT   \n","\n","    prediction_balanced_b  \n","0                     TIN  \n","1                     TIN  \n","2                     NOT  \n","3                     NOT  \n","4                     NOT  \n","..                    ...  \n","855                   TIN  \n","856                   NOT  \n","857                   UNT  \n","858                   NOT  \n","859                   NOT  \n","\n","[860 rows x 4 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["prediction = run_model(balanced_model, train_x, train[\"subtask_b\"], test_x)\n","test['prediction_balanced_b'] = prediction\n","test[['id', 'tweet', 'subtask_b', 'prediction_balanced_b']]"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"cUiesVXLLCKt"},"source":["The new model should reduce the differences between `accuracy` and `binary f1` and `micro f1` and `macro f1` respectively. You will observe some decrease in `accuracy` and `micro f1` scores, but at the same time `binary f1` and `macro f1` will improve significantly:\n","\n","> \\*\\*\\* SubTask A \\*\\*\\*  \n","accuracy: 0.78  \n","binary f1: 0.61  \n",">\n","> \\*\\*\\* SubTask B \\*\\*\\*  \n","micro f1: 0.75  \n","macro f1: 0.59"]},{"cell_type":"code","execution_count":39,"metadata":{"deletable":false,"editable":false,"id":"Kr4t-7UpLCKt"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** SubTask A ***\n","accuracy: 0.78\n","binary f1: 0.61\n","\n","*** SubTask B ***\n","micro f1: 0.75\n","macro f1: 0.59\n"]}],"source":["print(\"*** SubTask A ***\")\n","print(f\"accuracy: {accuracy_score(test['subtask_a'], test['prediction_balanced_a']):0.2f}\")\n","print(f\"binary f1: {f1_score(test['subtask_a'], test['prediction_balanced_a'], average='binary'):0.2f}\")\n","print(\"\")\n","print(\"*** SubTask B ***\")\n","print(f\"micro f1: {f1_score(test['subtask_b'], test['prediction_balanced_b'], average='micro'):0.2f}\")\n","print(f\"macro f1: {f1_score(test['subtask_b'], test['prediction_balanced_b'], average='macro'):0.2f}\")"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"sruWQSBYLCKu"},"source":["## Additional Features - [3 Marks]\n","\n","When working with linear classifiers for Text Classification, if additional information related to the input texts is available, it is often a good idea to incorporate this information in the form of additional features to the text representation. In this assignment, the result of a Sentiment Analysis on the tweets is provided in the *sentiment* column of the `DataFrames`. The goal of this last exercise is to incorporate this information into the input vectors of the `LogisticRegression`.\n","\n","There are different ways to achieve this using **scikit-learn**, but a very handy approach, especially in combination with **pandas** `DataFrame`, is to create a [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). A `ColumnTransformer` can apply different encoding approaches to different columns of the input data separately and concatenate them to generate a single feature vector.\n","\n","You must complete the code for the `create_column_transformer` function. The function must create and return a `ColumnTransformer` with two transformers: \n","\n","*  A `TfidfVectorizer` that should be applied to the text of the tweets.\n","*  A [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) that should encode the annotations of the Sentiment Analysis.\n","\n","You must use the default parameters for both transformers. "]},{"cell_type":"code","execution_count":40,"metadata":{"id":"NFy3FbQ-LCKu"},"outputs":[],"source":["def create_column_transformer():\n","    column_transformer = ColumnTransformer(\n","        transformers=[\n","            ('tfidf', create_tfidfvectorizer(), 'tweet'),\n","            ('onehot', OneHotEncoder(), ['sentiment'])\n","        ]\n","    )\n","\n","\n","    return column_transformer"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"IjuHS56PLCKu"},"source":["The `ColumnTransformer` can now be run using the `run_vectorizer` function you implemented above. Notice that, in this case, the whole train and test `DataFrames` are passed to `run_vectorizer` along with the `ColumnTransformer`. However, the code of the function should be able to train and run it. The output of the new feature extraction strategy should be a vector of 19086 dimensions per tweet, 3 more dimensions that the previous approach:\n","\n","> Shape of train input data: (13240, 19086)  \n","Shape of test input data: (860, 19086)"]},{"cell_type":"code","execution_count":41,"metadata":{"deletable":false,"editable":false,"id":"y6vsZKHsLCKu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of train input data: (13240, 19086)\n","Shape of test input data: (860, 19086)\n"]}],"source":["column_transformer = create_column_transformer()\n","train_x_sentiment, test_x_sentiment = run_vectorizer(column_transformer, train, test)\n","print(f\"Shape of train input data: {train_x_sentiment.get_shape()}\")\n","print(f\"Shape of test input data: {test_x_sentiment.get_shape()}\")"]},{"cell_type":"code","execution_count":42,"metadata":{"deletable":false,"editable":false,"id":"SgBaUgRvLCKu"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_a</th>\n","      <th>prediction_sentiment_a</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet  subtask_a  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       True   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...      False   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...      False   \n","3    13876  #Watching #Boomer getting the news that she is...      False   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       True   \n","..     ...                                                ...        ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       True   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...      False   \n","857  67018  3 people just unfollowed me for talking about ...       True   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...      False   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL      False   \n","\n","     prediction_sentiment_a  \n","0                      True  \n","1                     False  \n","2                     False  \n","3                     False  \n","4                     False  \n","..                      ...  \n","855                    True  \n","856                   False  \n","857                    True  \n","858                    True  \n","859                   False  \n","\n","[860 rows x 4 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["prediction = run_model(balanced_model, train_x_sentiment, train[\"subtask_a\"], test_x_sentiment)\n","test['prediction_sentiment_a'] = prediction\n","test[['id', 'tweet', 'subtask_a', 'prediction_sentiment_a']]"]},{"cell_type":"code","execution_count":43,"metadata":{"deletable":false,"editable":false,"id":"ybS40mPNLCKu"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_b</th>\n","      <th>prediction_sentiment_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>15923</td>\n","      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n","      <td>TIN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27014</td>\n","      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30530</td>\n","      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13876</td>\n","      <td>#Watching #Boomer getting the news that she is...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>60133</td>\n","      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n","      <td>TIN</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>855</th>\n","      <td>73439</td>\n","      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n","      <td>TIN</td>\n","      <td>TIN</td>\n","    </tr>\n","    <tr>\n","      <th>856</th>\n","      <td>25657</td>\n","      <td>#MeetTheSpeakers 🙌 @USER will present in our e...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>857</th>\n","      <td>67018</td>\n","      <td>3 people just unfollowed me for talking about ...</td>\n","      <td>UNT</td>\n","      <td>UNT</td>\n","    </tr>\n","    <tr>\n","      <th>858</th>\n","      <td>50665</td>\n","      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>859</th>\n","      <td>24583</td>\n","      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n","      <td>NOT</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>860 rows × 4 columns</p>\n","</div>"],"text/plain":["        id                                              tweet subtask_b  \\\n","0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...       TIN   \n","1    27014  #ConstitutionDay is revered by Conservatives, ...       NOT   \n","2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       NOT   \n","3    13876  #Watching #Boomer getting the news that she is...       NOT   \n","4    60133  #NoPasaran: Unity demo to oppose the far-right...       TIN   \n","..     ...                                                ...       ...   \n","855  73439  #DespicableDems lie again about rifles. Dem Di...       TIN   \n","856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...       NOT   \n","857  67018  3 people just unfollowed me for talking about ...       UNT   \n","858  50665  #WednesdayWisdom Antifa calls the right fascis...       NOT   \n","859  24583      #Kavanaugh typical #liberals , #Democrats URL       NOT   \n","\n","    prediction_sentiment_b  \n","0                      TIN  \n","1                      NOT  \n","2                      NOT  \n","3                      NOT  \n","4                      NOT  \n","..                     ...  \n","855                    TIN  \n","856                    NOT  \n","857                    UNT  \n","858                    NOT  \n","859                    NOT  \n","\n","[860 rows x 4 columns]"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["prediction = run_model(balanced_model, train_x_sentiment, train[\"subtask_b\"], test_x_sentiment)\n","test['prediction_sentiment_b'] = prediction\n","test[['id', 'tweet', 'subtask_b', 'prediction_sentiment_b']]"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"id":"jiA7iOFYLCKu"},"source":["The addition of the Sentiment Analysis to the input feature vector should help in both **SubTask A** and **SubTask B**. All the metrics should get some improvement, especially `binary f1` and `macro f1`:\n","\n","> \\*\\*\\* SubTask A \\*\\*\\*  \n","accuracy: 0.79  \n","binary f1: 0.66    \n",">\n","> \\*\\*\\* SubTask B \\*\\*\\*  \n","micro f1: 0.77  \n","macro f1: 0.62"]},{"cell_type":"code","execution_count":44,"metadata":{"deletable":false,"editable":false,"id":"TI86qArGLCKu"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** SubTask A ***\n","accuracy: 0.79\n","binary f1: 0.66\n","\n","*** SubTask B ***\n","micro f1: 0.77\n","macro f1: 0.61\n"]}],"source":["print(\"*** SubTask A ***\")\n","print(f\"accuracy: {accuracy_score(test['subtask_a'], test['prediction_sentiment_a'] ):0.2f}\")\n","print(f\"binary f1: {f1_score(test['subtask_a'], test['prediction_sentiment_a'], average='binary'):0.2f}\")\n","print(\"\")\n","print(\"*** SubTask B ***\")\n","print(f\"micro f1: {f1_score(test['subtask_b'], test['prediction_sentiment_b'], average='micro'):0.2f}\")\n","print(f\"macro f1: {f1_score(test['subtask_b'], test['prediction_sentiment_b'], average='macro'):0.2f}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
